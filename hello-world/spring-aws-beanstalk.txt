Github URL for learning:
https://github.com/in28minutes/deploy-spring-boot-aws-eb

AWS url:
aws.amazon.com
user: kanishk.bhatt@publicissapient.com
pass: Neymar@11

Console:
console.aws.amazon.com

IAM users:
Root user have acces for everything including deleting account/billing etc
Better to create IAM user who can have programatic/console access and this new user and password should be used
We can restrict the IAM user roles based on Group and policy. Dev and QA should use this
Root user should be sued by owner and higher level stake holders only

Main benefit of cloud is on demand resource allocation: We can aquire machines the moment we need it
hence during peakload we can get benefits of it, and later on we can scale down

Above sapient account do not work so created new account:
root user: kanishkeminem@gmail.com/ kbhatt23 -> Suarez@23

IAM gorup : kbhatt23_dev
User: kbhatt23_dev1/Neymar@11
IAM user login URL : https://238067488952.signin.aws.amazon.com/console

Elastic IP is always static and hence after restarting EC2 the public ip/DNS might change but elastic ip will be same
This will be the ip for the users to access the application
EC2 is the virtual service 
Elasic bean stalke created below things on its won:
a. EC2 instance
b. load balancer in case of multi clusterd application
c. DNS,public IP and elastic IP(always remains same even after machine restart)
d. S3 : data stoarage hardware/Volumes

Default port for AWS beanstalk is 5000

Nginx is an api gateway like apigee or zuul
default port of nginx is 80 so if we give just host and run the app automatically it goes to port 80
chrome also looks for defsault port 80
EBS uses nginx as api gateway

hhtpd/apache server is the api gateway for tomcat deployment in EBS unlike java jar whihc is nginx

While using RDS in Bean stalk ,Application in bean stalk expects rds details like hostname, password, etc
These are auto configured while creating app if we select RDS configuration
This RDS config environment variables are only passed when we create RDS while creating elasitc bean stalk environment of application
If we terminate the environment RDS will also get terminated

We can link different instance of EC2 and RDS using security group
If we want to allow any one service to be called from everywhere we can go to security role of that service
-> and under inboud we can add new config

- in case RDS is created while configuring the elastic bean stalk it it coupled together.
If bean stalk application is deleted it deletes the RDS as well
But if we want DB to be shared in multiple application it is better to seperate RDS with elsatic bean stalk

While changing active profile in bean stalk application use follwing env variable:
SPRING_PROFILES_ACTIVE : dev

Application built on static framework like react/html can be hosted on data store like S3 in AWS.
We can create a bucket with public access and upload the npm built file .
Then we can expose the bucket ->  We can choose static website hosting option in S3
S3 i a global data store meanig even thought it is created in a specific region, all other regio's application can make use of this.
It is supposed to be 99.99999.. % durable anad availability of data is high
 
While patching docker images to AWS elastic beanstalk we need a son file with name: Dockerrun.aws.json

In case of multi container application Elastic beanstlak do not create reverse proxy of nginx as there could be more than one port ot be exposed.
In that case we need to go to EC2 instance of the app and allow inbound to all public domains in security groups
Multi conmtianer application need multi container docker option while creating envrionment in AWS elastic bean stalk

commands to create application using EB CLI:
a. eb init : to initialize and create config file : we can create new application here as well
b eb deploy: if init is done we can customize config.yml file and then use this command to deploy and restart the jar/war/docker image
c. eb list: list down applications and environment
d. eb list -v : a bit more data from c
e. eb health : show health related data
f. eb events : show events logs
g. eb config : show all config data in txt file. we can save the file and it reflects directly
h. eb printenv : prints environemnt variables set
i. eb terminate : terminate the environemtn of application
j. eb restore : restor the terminated env
- eb logs : last 100 lines of logs

Worker Service in Elastic bean stalk is used as a batch process running behind the scene. We can add data in Queue to be processed
SQL will send data from queue to root url ("/") endpoint and expect 200 as success and others as failure.
In case of success data messgae is removed form queue otheriwse it remians in queue and is retired after 5 minutes(default)
Endpoint type should be post as request body is sent from Queue as a message
- worker environment will not be exposed to public,  instead a SQS will be attached to it

SQL contains two queue for worker by default -> one queue for new items and one for error processed itme ready for retrying in 5 minutes by default

The expectation of usage for worker environment is that the time to porcess one request is huge like DB migration etc.
Hence rery and sending of queue will be slow and sent one by one

Steps to create loadbalanced application environment in Elastic bean stalk
a. create application
b. create environment , select configuration options before createing button
c. configure number of instances min and max : 
 - > in capacity select load balanced instance and put min and max instance
d. confifure rule for upscale and down scale : -> will create clooud watch alarms
 - > In sacling trigger section of capacity tag select type like cpu utilization based, or request based(for learning and demo)

e. configure load balancer
 - > Go to load balancer tag option and select default one and add health check endpoint -> used for livenessprobe 
e. configure rolling ipdate feature : -> gets called when a new fresh deployment is done

In Elastic bean stalk autosacling means sclaing up another instance of ec2, whihs is replica of smae and the load from network is shared by elastic load balancer
Elastic load balancer _ need to check for these EC2 instances even existing in different zones but within same region(for disaster management)


Cloud watch looks for conditions for max and min rolling updates and once that condition is met alarm is set
state change of cloud watch from om to alarm -> then it triggers the actions which is adding/cutting one instance of EC2 server.
After this is done state of cloud watch changes from alarm to ok.
Cloud watch uses auto scalable group for scheduling the EC2 instance in different zones of same region.
Types of deployment stragies:
a. rolling : first a new instance is made up one of existing is made down and so on . At any time number of live instance will be less than max amount
eg> for first time it will be load balanaced using elastic load balancer among 2 instances while first one is rolled out

b. rolling with batch: it creates a fresh new batch of new versiona nd then only it degrades, so at any time it will be more number of instances than max
eg. for first one it will be 4 and so on
c.. immutable :freshly creata  new auto scalable group with all 4 instnace of new verison code ,
 at that time it will have 8 instances load balanced 4 of old and 4 of new. then suddenly old auto scalable grou is terminated and 4 instances are left for load balancing

In all cases load balancer will have new and old version of code running and served to the client
In rolling it is slowest,
In rolling with natch it can be smade faster
but in immutable we have great option of quick roll back as it happens on just one click

custom build spec name:
buildspec-config.yml